{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vchavez-17/BootCamp_1/blob/master/M02_S04_Completo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " `Manipulación de tipos de datos y strings`\n",
        "\n",
        "##  Objetivo\n",
        "\n",
        "Explorar y aplicar técnicas de manipulación de tipos de datos y cadenas de texto en pandas, facilitando la transformación y análisis de datos con python.\n",
        "\n",
        "---\n",
        "\n",
        "##  Comencemos\n",
        "\n",
        "La manipulación de tipos de datos y strings es esencial para asegurar que tus datos estén en el formato correcto para el análisis. Pandas ofrece herramientas poderosas para transformar y manejar datos de manera eficiente.\n",
        "\n",
        "---\n",
        "\n",
        "##  **Manipulación de tipos de datos**\n",
        "\n",
        "###  **Casting básico con `astype()`**\n",
        "\n",
        "El casting con `astype()` te permite cambiar el tipo de datos de las columnas en un DataFrame, lo cual es bastante útil para asegurar que los datos sean del tipo correcto para realizar operaciones específicas, de analítica o visualización."
      ],
      "metadata": {
        "id": "P-ttYVDfwsW9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "SfDNLf7cwc8N",
        "outputId": "fde7b43c-3a36-4d18-8d84-ed6410cba51c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A             int64\n",
              "B           float64\n",
              "C    datetime64[ns]\n",
              "D    datetime64[ms]\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C</th>\n",
              "      <td>datetime64[ns]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D</th>\n",
              "      <td>datetime64[ms]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "df = pd.DataFrame({\n",
        "    'A': ['1', '2', '3', '4'],\n",
        "    'B': [1.1, 2.2, 3.3, 4.4],\n",
        "    'C': ['2021-01-01', '2021-02-01', '2021-03-01', '2021-04-01'],\n",
        "    'D': [1212883200000, 1296518400000, 1327881600000, 1361923200000]\n",
        "})\n",
        "\n",
        "# Convertir la columna 'A' a tipo entero\n",
        "df['A'] = df['A'].astype(int)\n",
        "\n",
        "# Convertir la columna 'C' a tipo datetime usando pd.to_datetime\n",
        "df['C'] = pd.to_datetime(df['C'])\n",
        "\n",
        "# Convertir la columna 'D' a tipo datetime en milisegundos\n",
        "df = df.astype({'D': 'datetime64[ms]'})\n",
        "\n",
        "# Mostrar los tipos de datos para verificar las conversiones\n",
        "df.dtypes\n",
        "\n",
        "# Salida esperada:\n",
        "# A             int64\n",
        "# B           float64\n",
        "# C    datetime64[ns]\n",
        "# D    datetime64[ns]\n",
        "# dtype: object"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Casting de tipos numéricos con `to_numeric()`**\n",
        "\n",
        "Para convertir columnas a tipos numéricos, puedes usar `pd.to_numeric()`, que ofrece más control sobre cómo manejar valores no convertibles, como la capacidad de convertirlos en NaN o ignorarlos."
      ],
      "metadata": {
        "id": "ka8dKVKew3Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame de ejemplo\n",
        "df = pd.DataFrame({\n",
        "    'A': ['1', '2', '3', '4'],\n",
        "    'B': ['1.1', '2.2', '3.3', '4.4']\n",
        "})\n",
        "\n",
        "# Convertir la columna 'A' a tipo float usando to_numeric\n",
        "df['A'] = pd.to_numeric(df['A'])\n",
        "\n",
        "# Mostrar los tipos de datos para verificar las conversiones\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "BsHrpgTJw2v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Control de errores en el casting**\n",
        "\n",
        "Es crucial manejar los posibles errores que puedan surgir durante el proceso de casting. Tanto `pd.to_numeric()` como `pd.to_datetime()` permiten especificar el parámetro `errors` para controlar cómo se manejan los errores, lo cual no está disponible en `astype()`.\n"
      ],
      "metadata": {
        "id": "xrMbNmaAw7Ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame de ejemplo con datos no convertibles\n",
        "df = pd.DataFrame({\n",
        "    'A': ['1', '2', 'three', '4'],\n",
        "    'B': ['1.1', 'two.point.two', '3.3', '4.4']\n",
        "})\n",
        "\n",
        "# Intentar convertir la columna 'A' a tipo entero, con manejo de errores\n",
        "df['A'] = pd.to_numeric(df['A'], errors='coerce')\n",
        "\n",
        "# Intentar convertir la columna 'B' a tipo float, con manejo de errores\n",
        "df['B'] = pd.to_numeric(df['B'], errors='coerce')\n",
        "\n",
        "# Nostrar el dataframe resultante\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ZnEz1H8ow9rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Tipo de Error   | Descripción                                                                 |\n",
        "|-----------------|-----------------------------------------------------------------------------|\n",
        "| `errors='raise'`  | Genera una excepción si se encuentra un valor no convertible (comportamiento predeterminado). |\n",
        "| `errors='coerce'` | Convierte los valores no convertibles en NaN (valores faltantes).           |\n",
        "| `errors='ignore'` | Deja los valores no convertibles tal como están, sin realizar el casting.   |\n",
        "\n",
        "---\n",
        "\n",
        "##  **Manipulación de cadenas de texto**\n",
        "\n",
        "La manipulación de cadenas de texto puede incluir tareas como cambiar a minúsculas, eliminar espacios, reemplazar caracteres, y más. Aquí hay algunos métodos comunes para trabajar con strings en Pandas.\n",
        "\n",
        "###  **Manipulación de strings**\n",
        "\n",
        "Pandas proporciona una propiedad especial `.str` que te permite acceder a métodos de manipulación de strings, como `lower()`, `upper()`, `strip()`, `replace()`, y `split()`, entre otros. Estos métodos son vectorizados, lo que significa que se aplican a todos los elementos de una columna de manera eficiente."
      ],
      "metadata": {
        "id": "FXitu3FBxAfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame de ejemplo\n",
        "df = pd.DataFrame({\n",
        "    'Nombres': ['John Doe', 'Jane Smith', 'Alice Johnson'],\n",
        "    'Emails': ['john.doe@example.com', 'jane.smith@example.com', 'alice.johnson@example.com']\n",
        "})\n",
        "\n",
        "# Convertir a minúsculas\n",
        "df['Nombres'] = df['Nombres'].str.lower()\n",
        "\n",
        "# Dividir la columna 'Nombres' en dos columnas\n",
        "df[['Nombre', 'Apellido']] = df['Nombres'].str.split(' ', expand=True)\n",
        "\n",
        "# Extraer el dominio de los correos electrónicos\n",
        "df['Dominio'] = df['Emails'].str.split('@').str[1]\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "0xtHVbaTxBgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Métodos populares para manipulación de strings**\n",
        "\n",
        "| Método              | Descripción                                         |\n",
        "|---------------------|-----------------------------------------------------|\n",
        "| `str.lower()`       | Convierte todas las cadenas a minúsculas            |\n",
        "| `str.upper()`       | Convierte todas las cadenas a mayúsculas            |\n",
        "| `str.strip()`       | Elimina los espacios en blanco al inicio y al final |\n",
        "| `str.replace(a, b)` | Reemplaza todas las apariciones de `a` por `b`      |\n",
        "| `str.split(sep)`    | Divide la cadena en una lista utilizando `sep` como separador |\n",
        "\n",
        "Estos métodos son muy útiles para transformar y limpiar datos textuales en tus DataFrames.\n",
        "\n",
        "---\n",
        "\n",
        "###  **Notas**\n",
        "\n",
        "Pandas proporciona estructuras de datos de alto nivel y herramientas de análisis de datos. Algunas de las características clave de Pandas son:\n",
        "\n",
        "- **Optimización**: Pandas está construido sobre NumPy, aprovechando algoritmos compilados en C para operaciones vectorizadas rápidas.\n",
        "\n",
        "- **Gestión de memoria**: Utiliza `BlockManager` para almacenar datos de forma flexible y manejar tipos heterogéneos, a diferencia del almacenamiento contiguo de NumPy.\n",
        "\n",
        "- **Extensibilidad**: Además del análisis de datos, Pandas se expande con APIs como `GeoPandas` para análisis geoespacial y `Pandas TA` para el trading.\n",
        "\n",
        "- **Aplicaciones industriales**: Usado en finanzas para análisis cuantitativo, en biotecnología para datos genómicos, y otros campos que gestionan datos complejos.\n",
        "\n",
        "- **Interoperabilidad con SQL**: Permite la interacción directa con bases de datos SQL, facilitando la carga y manipulación avanzada de datos en `DataFrames`.\n",
        "\n",
        "NumPy es una librería de Python que proporciona soporte para arreglos y matrices multidimensionales, junto con una colección de funciones matemáticas de alto nivel para operar con estos arreglos.---"
      ],
      "metadata": {
        "id": "gg2cfZUfxIIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        " `Técnicas avanzadas de filtrado en dataframes`\n",
        "\n",
        "##  Objetivo\n",
        "\n",
        "Desarrollar habilidades para aplicar técnicas avanzadas de filtrado en dataframes de pandas, permitiendo seleccionar y manipular datos para análisis específicos y extracción de información relevante.\n",
        "\n",
        "---\n",
        "\n",
        "##  Comencemos\n",
        "\n",
        "El filtrado avanzado es esencial en el análisis de datos, permitiendo extraer subconjuntos de datos basados en condiciones específicas, se puede realizar, por ejemplo, para seleccionar columnas específicas, filtrar datos de texto o aplicar filtros booleanos para extraer datos que cumplen con ciertas condiciones.\n",
        "\n",
        "---\n",
        "\n",
        "##  **Técnicas avanzadas de filtrado en dataframes**\n",
        "\n",
        "###  **Creación del dataframe general:**"
      ],
      "metadata": {
        "id": "Qn_H0QKjxSIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "df = pd.DataFrame({\n",
        "    'Nombre': ['Ana', 'Luis', 'Carmen', 'José', 'Elena', 'Juan'],\n",
        "    'Edad': [25, 30, 22, 27, 31, 19],\n",
        "    'Ciudad': ['Tokio', 'Moscú', 'Londres', 'París', 'Sídney', 'Ciudad de México'],\n",
        "    'Puntuación': [85, 88, 90, 95, 82, 78],\n",
        "    'Ocupación': ['Estudiante', 'Ingeniero', 'Estudiante', 'Doctor', 'Arquitecto', 'Estudiante']\n",
        "})\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "4XMDfVzYxHA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uso del método `filter()`:**\n",
        "\n",
        "Pandas permite filtrar datos usando el método `filter()`, que puede ser útil para seleccionar **`columnas específicas`** de un DataFrame basado en etiquetas o condiciones de contenido."
      ],
      "metadata": {
        "id": "1D-jo93Lxctc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar columnas por nombres que contienen ciertas letras\n",
        "df_filtrado = df.filter(like='Nombre')\n",
        "df_filtrado.head(10)"
      ],
      "metadata": {
        "id": "djthKRvUxfMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar columnas por nombres específicos\n",
        "df_filtrado = df.filter(items=['Nombre', 'Edad', 'Ciudad'])\n",
        "df_filtrado.head(10)"
      ],
      "metadata": {
        "id": "HsUv3Fubxl3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Aplicación de filtros de texto:**\n",
        "\n",
        "Pandas permite filtrar datos de texto en columnas de un DataFrame, utilizando métodos específicos como `str.contains()` para seleccionar filas que contienen una cadena de texto en particular.\n"
      ],
      "metadata": {
        "id": "O6xH1YIgxnMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar filas por ciudad que contienen la letra 'T'\n",
        "df_filtrado = df[df['Ciudad'].str.contains('T')]\n",
        "df_filtrado.head(10)"
      ],
      "metadata": {
        "id": "jV5LRwTixph_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Aplicación de filtros booleanos:**\n",
        "\n",
        "Los filtros booleanos son expresiones que resultan en `True` o `False` para cada fila del DataFrame, permitiendo extraer datos que cumplen con una condición específica."
      ],
      "metadata": {
        "id": "NGjqHaGgxuFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar filtro booleano para seleccionar personas mayores de 25 años\n",
        "df_filtrado = df[df['Edad'] > 25]\n",
        "df_filtrado.head(10)\n"
      ],
      "metadata": {
        "id": "TX_toLUKxvsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar filtro booleano para seleccionar personas con puntuación mayor o igual a 85\n",
        "df_filtrado = df[df['Puntuación'] >= 85]\n",
        "df_filtrado.head(10)"
      ],
      "metadata": {
        "id": "-dlO6xZRxx0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Filtros complejos con múltiples condiciones:**\n",
        "\n",
        "En Pandas, al aplicar filtros en DataFrames, se requiere el uso de operadores lógicos específicos para realizar operaciones element-wise sobre matrices de NumPy. En lugar de los operadores estándar de Python (and, or, not), se utilizan:\n",
        "\n",
        "- **`&`** para **AND**\n",
        "- **`|`** para **OR**\n",
        "- **`~`** para **NOT**"
      ],
      "metadata": {
        "id": "qH7dFsbAxzi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar filas donde (Edad < 31) y (Ocupación es 'Estudiante')\n",
        "df_filtrado_and = df[(df['Edad'] < 31) & (df['Ocupación'] == 'Estudiante')]\n",
        "df_filtrado_and.head()\n",
        "\n",
        "# Seleccionar filas donde (Edad < 30) o (Puntuación es igual a 85)\n",
        "df_filtrado_or = df[(df['Edad'] < 30) | (df['Puntuación'] == 85)]\n",
        "df_filtrado_or.head()\n",
        "\n",
        "# Seleccionar filas donde (Ocupación no es 'Estudiante')\n",
        "df_filtrado_not = df[~(df['Ocupación'] == 'Estudiante')]\n",
        "df_filtrado_not.head()"
      ],
      "metadata": {
        "id": "jt3xZ_Crx1ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Notas:**\n",
        "\n",
        "1. **Usa filtros booleanos para condiciones simples**: Para condiciones básicas, los filtros booleanos son una forma eficiente de seleccionar datos.\n",
        "\n",
        "2. **Usa filter() para seleccionar columnas**: Si necesitas seleccionar columnas específicas, el método filter() es una opción rápida y sencilla.\n",
        "\n",
        "3. **Usa operadores lógicos para múltiples condiciones**: Al combinar condiciones, recuerda usar los operadores lógicos adecuados para obtener los resultados esperados.\n",
        "\n",
        "4. **Agrupa condiciones con paréntesis**: Para evitar errores de precedencia, agrupa las condiciones con paréntesis para asegurar que las operaciones se realicen en el orden correcto."
      ],
      "metadata": {
        "id": "cHTzy-K0x314"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#Ejercicio 01: Limpieza y conversión de datos\n",
        "\n",
        "##  Objetivo\n",
        "\n",
        " Aplicar técnicas de limpieza y conversión de datos para transformar un dataframe con datos sucios en un formato más estructurado y manejable.\n",
        "\n",
        "---\n",
        "\n",
        "## Desarrollo\n",
        "\n",
        "1. **Generar un dataframe con valores aleatorios**:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Crear un DataFrame de ejemplo con datos sucios\n",
        "def create_dirty_data(num_rows):\n",
        "    np.random.seed(0)  # Para reproducibilidad\n",
        "\n",
        "    # Generar datos aleatorios para cada columna\n",
        "    nombres = [f'Nombre_{i}' for i in range(num_rows)]\n",
        "    edades = np.random.choice(['25', '30', '22', '27', '31 años', '19', 'not available', ''], num_rows)\n",
        "    ciudades = np.random.choice(['Tokio', 'Moscú', 'Londres', 'París ', 'Sídney', 'Ciudad de México', '   ', '', 'Moscú   '], num_rows)\n",
        "    puntuaciones = np.random.choice(['85', '88', '90.5', '95', '82', 'setenta y ocho', '', 'NaN'], num_rows)\n",
        "    ocupaciones = np.random.choice(['Estudiante', 'Ingeniero', 'Estudiante', 'Doctor', 'Arquitecto', 'Estudiante ', ''], num_rows)\n",
        "    fechas = np.random.choice(['2021-01-01', '2021-02-01', 'not available', '2021-04-01', '2021-05-01', '2021/06/01', '01-07-2021'], num_rows)\n",
        "    precios = np.random.choice(['100.50', '200', 'not a number', '150.75', '200.00', '250.10', '', 'NaN'], num_rows)\n",
        "    cantidades = np.random.choice(['1', 'two', '3', '4', 'five', '6', '', 'NaN'], num_rows)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'Nombre': nombres,\n",
        "        'Edad': edades,\n",
        "        'Ciudad': ciudades,\n",
        "        'Puntuación': puntuaciones,\n",
        "        'Ocupación': ocupaciones,\n",
        "        'Fecha de Compra': fechas,\n",
        "        'Precio Unitario': precios,\n",
        "        'Cantidad': cantidades\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "# Crear un DataFrame con 200 datos sucios\n",
        "df_dirty = create_dirty_data(250)\n",
        "df_dirty.head()\n",
        "```\n",
        "---\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "1. **Conversión de datos**: Convierte los siguientes campos a su tipo de dato correspondiente, tratando cualquier valor no convertible como `NaN`\n",
        "   - `'Edad'`.\n",
        "   - `'Puntuación'`.\n",
        "   - `'Precio Unitario'`.\n",
        "   - `'Cantidad'`.\n",
        "   - `'Fecha de Compra'`.\n",
        "\n",
        "2. **Limpieza de espacios**:\n",
        "   - Elimina espacios en blanco al inicio y al final de los valores en las columnas `'Nombre'`, `'Ciudad'`, y `'Ocupación'`.\n",
        "   - Reemplaza los valores vacíos en `'Ciudad'` y `'Ocupación'` por `'Desconocida'`.\n",
        "\n",
        "3. **Llenado de `NaN`**:\n",
        "   - Rellena los valores `NaN` en las columnas `'Edad'`, `'Puntuación'`, `'Precio Unitario'`, y `'Cantidad'` con la mediana de la columna respectiva.\n",
        "   - Rellena los valores `NaN` en las columnas `'Ciudad'` y `'Ocupación'` con `'Desconocida'`.\n",
        "   - Rellena los valores `NaT` en la columna `'Fecha de Compra'` con la fecha actual.\n",
        "\n",
        "4. **Mostrar el dataframe actualizado**:\n",
        "   - Muestra el dataframe resultante después de aplicar las transformaciones.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "1yAiT7u4x-5L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lp4Z16bzyP-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        " `Ordenamiento y transformación de dataframes`\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Desarrollar habilidades para ordenar y transformar dataframes en Pandas, utilizando métodos como `sort`, `map`, y `apply` para organizar datos y aplicar funciones que mejoran el análisis y la presentación de información.\n",
        "\n",
        "---\n",
        "\n",
        "## Comencemos\n",
        "\n",
        "Ordenar y transformar Dataframes son técnicas esenciales en el análisis de datos, permitiendo no solo organizar la información de manera más efectiva, sino también aplicar transformaciones específicas para preparar los datos para análisis posteriores.\n",
        "\n",
        "---\n",
        "\n",
        "## **Técnicas de ordenamiento y transformación en dataframes**\n",
        "\n",
        "### **Creación del dataframe general:**"
      ],
      "metadata": {
        "id": "OnRKdeRpyRl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de ejemplo con datos de pacientes en un hospital\n",
        "df = pd.DataFrame({\n",
        "    'Paciente': ['John Smith', 'Laura Jones', 'Gary White', 'Sonia Taylor', 'Raj Patel', 'Emily Howard', 'Bruce Wayne', 'Clark Kent', 'Diana Prince', 'Peter Parker'],\n",
        "    'Edad': [28, 34, 22, 45, 30, 26, 40, 35, 32, 29],\n",
        "    'Diagnóstico': ['Apendicitis', 'Fractura de brazo', 'Gripe', 'Diabetes Tipo 2', 'Hipertensión', 'Alergias', 'Anemia', 'Bronquitis', 'Artritis', 'Quemaduras leves'],\n",
        "    'Días Hospitalizado': [3, 5, 2, 7, 3, 1, 4, 6, 5, 2],\n",
        "    'Costo del Tratamiento ($)': [1500, 3000, 200, 5000, 1000, 300, 1200, 1800, 2500, 500]\n",
        "})\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "RSG8M8QfyRQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ordenamiento de dataframes**\n",
        "\n",
        "La función `sort_values` permite ordenar un Dataframes por una o más columnas, facilitando la visualización y el análisis de datos de manera más efectiva."
      ],
      "metadata": {
        "id": "8XxkRLO8yxE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar renglones por la columna 'Edad' en orden ascendente\n",
        "df_ordenado = df.sort_values(by='Edad')\n",
        "df_ordenado.head(10)"
      ],
      "metadata": {
        "id": "sBvfqM6kyuIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar renglones por la columna 'Costo del Tratamiento ($)' en orden descendente\n",
        "df_ordenado = df.sort_values(by='Costo del Tratamiento ($)', ascending=False)\n",
        "df_ordenado.head(10)"
      ],
      "metadata": {
        "id": "oMMvkTCCy0ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar renglones por las columnas 'Edad' y 'Días Hospitalizado'\n",
        "df_ordenado = df.sort_values(by=['Edad', 'Días Hospitalizado'], ascending=[True, False])\n",
        "df_ordenado.head(10)"
      ],
      "metadata": {
        "id": "SJEoBBkYy2db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Transformación con `map` y `apply`**\n",
        "\n",
        "Estas funciones son útiles para realizar transformaciones específicas en los datos, permitiendo tanto cambios simples como operaciones más complejas en todo el Dataframes.\n",
        "\n",
        "#### Uso de `map` en una Serie:\n",
        "\n",
        "Recuerda que `map` es una función que se aplica a una Serie de Pandas, permitiendo mapear valores existentes a nuevos valores basados en un diccionario o función específica."
      ],
      "metadata": {
        "id": "T8wgA4iyy5xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Supongamos que necesitamos codificar la columna de 'Diagnóstico' para un análisis anónimo.\n",
        "diagnostico_codificado = {\n",
        "    'Apendicitis': 'D01',\n",
        "    'Fractura de brazo': 'D02',\n",
        "    'Gripe': 'D03',\n",
        "    'Diabetes Tipo 2': 'D04',\n",
        "    'Hipertensión': 'D05',\n",
        "    'Alergias': 'D06',\n",
        "    'Anemia': 'D07',\n",
        "    'Bronquitis': 'D08',\n",
        "    'Artritis': 'D09',\n",
        "    'Quemaduras leves': 'D10'\n",
        "}\n",
        "df['Diagnóstico Codificado'] = df['Diagnóstico'].map(diagnostico_codificado)\n",
        "df[['Diagnóstico', 'Diagnóstico Codificado']]"
      ],
      "metadata": {
        "id": "aX341twky73f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para categorizar edades\n",
        "def categorizar_edad(edad):\n",
        "    if edad < 30:\n",
        "        return '20-29 años'\n",
        "    elif edad < 40:\n",
        "        return '30-39 años'\n",
        "    elif edad < 50:\n",
        "        return '40-49 años'\n",
        "    else:\n",
        "        return '50+ años'\n",
        "\n",
        "# Aplicar map con una función para transformar las edades\n",
        "df['Grupo de Edad'] = df['Edad'].map(categorizar_edad)\n",
        "df[['Paciente', 'Edad', 'Grupo de Edad']]"
      ],
      "metadata": {
        "id": "Obv2Lunxy-j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#### Uso de `apply` en un dataframe:\n",
        "\n",
        "La función `apply` se utiliza para aplicar una función a lo largo de los renglones o columnas de un Dataframes, permitiendo realizar operaciones más complejas y personalizadas en los datos.\n",
        "\n",
        "- **Ejemplo de cálculo de costo por día hospitalizado:**"
      ],
      "metadata": {
        "id": "MjglJxQjzCRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el costo estimado del tratamiento por día hospitalizado\n",
        "df['Costo por Día'] = df.apply(lambda row: round(row['Costo del Tratamiento ($)'] / row['Días Hospitalizado'], 2), axis=1)\n",
        "df[['Paciente', 'Costo del Tratamiento ($)', 'Días Hospitalizado', 'Costo por Día']]"
      ],
      "metadata": {
        "id": "tF-uwvxkzEfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Ejemplo de ajuste de costo por días hospitalizados:**"
      ],
      "metadata": {
        "id": "5hK4y-znzGmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar el costo del tratamiento basado en el número de días hospitalizados\n",
        "def ajustar_costo(row):\n",
        "  descuento = 100 * (row['Días Hospitalizado'] - 1)  # $100 descuento por cada día 'ADICIONAL', no por el primero.\n",
        "  return row['Costo del Tratamiento ($)'] - descuento\n",
        "\n",
        "# Aplicar la función a lo largo de los renglones\n",
        "df['Costo Ajustado ($)'] = df.apply(ajustar_costo, axis=1)\n",
        "df[['Paciente', 'Días Hospitalizado', 'Costo del Tratamiento ($)', 'Costo Ajustado ($)']].head(10)"
      ],
      "metadata": {
        "id": "snU2kF2jzOAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Notas:**\n",
        "\n",
        "- `apply()`:\n",
        "Es notable por permitir la ejecución de funciones complejas y personalizadas en múltiples columnas de Dataframes, facilitando operaciones avanzadas como lógicas condicionales y manipulaciones de fechas, además de poder retornar múltiples valores nuevos desde una sola aplicación.\n",
        "\n",
        "- `map()`:\n",
        "Está optimizado para `Series`, siendo ideal para transformaciones eficientes utilizando diccionarios, otras Series o funciones, especialmente útil para codificaciones rápidas y conversión de datos categóricos con alineación automática de índices.\n",
        "\n",
        "- `sort_values()`:\n",
        "Permite un ordenamiento avanzado por múltiples columnas con criterios variables y la opción de aplicar transformaciones a datos antes del ordenamiento, además de manejar `NaNs`, mejorando la preparación de datos para análisis o visualización.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "PXWqQWStzLwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Combinación y agrupación de datos`\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Aprender a combinar y agrupar dataframes en Pandas para unificar datos de múltiples fuentes y realizar análisis estadísticos complejos mediante técnicas de `merge` y `groupby`.\n",
        "\n",
        "---\n",
        "\n",
        "## Comencemos\n",
        "\n",
        "Combinar y agrupar son técnicas fundamentales en el análisis de datos que facilitan la integración de información de diversas fuentes y la realización de análisis detallados sobre subconjuntos específicos de datos.\n",
        "\n",
        "---\n",
        "\n",
        "## **Técnicas de combinación y agrupación en dataframes**\n",
        "\n",
        "### **Creación de dataframes generales:**"
      ],
      "metadata": {
        "id": "vjB1hImfzcJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# DataFrame de Clientes\n",
        "clientes = pd.DataFrame({\n",
        "    'cliente_id': [101, 102, 103, 104],\n",
        "    'nombre': ['Alice Johnson', 'Bob Smith', 'Charlie Davis', 'Diana Prince'],\n",
        "    'email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'diana@example.com'],\n",
        "    'región': ['Norte', 'Sur', 'Este', 'Oeste']\n",
        "})\n",
        "clientes.head()"
      ],
      "metadata": {
        "id": "FQGMnQyCzfMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame de Pedidos\n",
        "pedidos = pd.DataFrame({\n",
        "    'pedido_id': ['P001', 'P002', 'P003', 'P004', 'P005', 'P006'],\n",
        "    'cliente_id': [101, 103, 105, 104, 101, 102],  # Incluye IDs que no existen y repeticiones\n",
        "    'total': [250, 150, 450, 300, 320, 110],\n",
        "    'fecha': ['2021-01-10', '2021-02-15', '2021-03-20', '2021-04-22', '2021-05-25', '2021-06-15'],\n",
        "    'categoría': ['Electrónica', 'Ropa', 'Electrónica', 'Libros', 'Alimentos', 'Ropa']\n",
        "})\n",
        "pedidos.head(10)"
      ],
      "metadata": {
        "id": "4P1WfI2RzhKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Merge de dataframes**\n",
        "\n",
        "La función `merge` en Pandas permite combinar dos o más DataFrames en función de una o más claves comunes, similar a un `JOIN` en SQL.\n",
        "\n",
        "\n",
        "### 🔦 **Ejemplos de uso de inner, left y right join:**"
      ],
      "metadata": {
        "id": "OLfibFEFzjRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inner Join\n",
        "df_inner = pd.merge(clientes, pedidos, on='cliente_id', how='inner')\n",
        "df_inner.head(10)\n"
      ],
      "metadata": {
        "id": "TQWfOgyfzoa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Left Join\n",
        "df_left = pd.merge(clientes, pedidos, on='cliente_id', how='left')\n",
        "df_left.head(10)\n"
      ],
      "metadata": {
        "id": "fg05KK0pzrPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Right Join\n",
        "df_right = pd.merge(clientes, pedidos, on='cliente_id', how='right')\n",
        "df_right.head(10)"
      ],
      "metadata": {
        "id": "Cv5ok9W5zsYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parámetros de `merge`\n",
        "\n",
        "| Parámetro    | Descripción                                                                                                             |\n",
        "|--------------|-------------------------------------------------------------------------------------------------------------------------|\n",
        "| `on`         | Nombre de la columna o lista de nombres de columnas para unir las tablas. Las columnas deben existir en ambos DataFrames.|\n",
        "| `how`        | Tipo de merge/join: 'left', 'right', 'outer', 'inner'. Por defecto es 'inner'.                                          |\n",
        "| `left_on`    | Columnas del DataFrame izquierdo para hacer el join si los nombres de las columnas en ambos DataFrames no coinciden.    |\n",
        "| `right_on`   | Columnas del DataFrame derecho para hacer el join si los nombres de las columnas en ambos DataFrames no coinciden.      |\n",
        "| `left_index` | Si es `True`, usa el índice (filas) del DataFrame izquierdo como su clave de join. Por defecto es `False`.              |\n",
        "| `right_index`| Si es `True`, usa el índice (filas) del DataFrame derecho como su clave de join. Por defecto es `False`.                |\n",
        "| `suffixes`   | Una tupla de strings para añadir a los nombres de columnas duplicadas que no son claves de join. Por defecto es `('_x', '_y')`. |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Agrupación de datos con `groupby`**\n",
        "\n",
        "La función `groupby` en Pandas permite agrupar datos en un Dataframes en función de una o más columnas, permitiendo realizar operaciones estadísticas y de agregación en los grupos resultantes.\n",
        "\n",
        "Algunas funciones de agregación comunes incluyen `sum`, `mean`, `count`, `min`, `max`, `std`, `var`, entre otras.\n",
        "\n",
        "### **Ejemplos de uso de groupby:**"
      ],
      "metadata": {
        "id": "qF-_w-oozuqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos un left join para obtener un DataFrame completo\n",
        "df_merged = pd.merge(clientes, pedidos, on='cliente_id', how='left')\n",
        "df_merged.head(10)"
      ],
      "metadata": {
        "id": "PeHoj_tbz6je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo 1: Total de Pedidos por Región\n",
        "total_por_región = df_merged.groupby('región')['total'].sum()\n",
        "print(total_por_región)\n",
        "\n",
        "# Ejemplo 2: Número de Pedidos por Categoría y Región\n",
        "conteo_pedidos_categoría = df_merged.groupby(['región', 'categoría'])['pedido_id'].count()\n",
        "print(conteo_pedidos_categoría)\n",
        "\n",
        "# Ejemplo 3: Promedio del Total de Pedidos por Mes\n",
        "# Convertir 'fecha' a datetime\n",
        "df_merged['fecha'] = pd.to_datetime(df_merged['fecha'])\n",
        "\n",
        "# Extraer el mes y año de la fecha\n",
        "df_merged['mes_año'] = df_merged['fecha'].dt.to_period('M')\n",
        "\n",
        "# Calcular el promedio de ventas por mes\n",
        "promedio_ventas_mes = df_merged.groupby('mes_año')['total'].mean()\n",
        "print(promedio_ventas_mes)"
      ],
      "metadata": {
        "id": "1OEfXStzz5Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Notas:**\n",
        "\n",
        "- **`merge`** puede ser utilizado no solo para combinar dos Dataframes basados en claves coincidentes, sino también para realizar left, right, y outer joins, proporcionando una flexibilidad comparable a las bases de datos relacionales.\n",
        "- **`groupby`** no solo es útil para sumar o promediar datos, sino que también puede ser utilizado para aplicar una multitud de funciones estadísticas, transformaciones personalizadas y filtrados complejos dentro de los grupos.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "OOitrauXz9n0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Ejercicio 02: Análisis de datos de tráfico en una ciudad`\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Aplicar técnicas de ordenamiento, transformación, combinación y agrupación en un dataframe que contiene datos de tráfico en una ciudad para identificar patrones de congestión y correlaciones con factores meteorológicos.\n",
        "\n",
        "---\n",
        "\n",
        "## Desarrollo\n",
        "\n",
        "1. **Generar un dataframe con valores aleatorios**:\n",
        "\n",
        "Contamos con dos dataframes que representan datos de tráfico y datos meteorológicos.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Generar datos para el DataFrame de tráfico\n",
        "np.random.seed(0)\n",
        "fechas_trafico = pd.date_range(start='2024-07-01', periods=30, freq='D')\n",
        "horas_trafico = ['08:00', '17:00']\n",
        "zonas_trafico = ['Centro', 'Norte', 'Sur', 'Este', 'Oeste']\n",
        "\n",
        "# Crear DataFrame de tráfico con 150 datos\n",
        "df_trafico = pd.DataFrame(\n",
        "    {\n",
        "      'fecha': np.tile(fechas_trafico, len(horas_trafico) * len(zonas_trafico)),\n",
        "      'hora': np.repeat(horas_trafico * len(fechas_trafico), len(zonas_trafico)),\n",
        "      'zona': np.tile(zonas_trafico, len(fechas_trafico) * len(horas_trafico)),\n",
        "      'vehiculos': np.random.randint(100, 500, size=(len(fechas_trafico) * len(horas_trafico) * len(zonas_trafico)))\n",
        "  }\n",
        ")\n",
        "\n",
        "# Crear DataFrame meteorológico con 30 días de datos\n",
        "df_meteorologico = pd.DataFrame(\n",
        "    {\n",
        "      'fecha': fechas_trafico,\n",
        "      'temperatura': np.random.uniform(25, 35, size=len(fechas_trafico)),\n",
        "      'precipitacion': np.random.uniform(0, 10, size=len(fechas_trafico))\n",
        "  }\n",
        ")\n",
        "```\n",
        "---\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "1. **Ordenar datos de tráfico:**\n",
        "   - Ordena el DataFrame de tráfico por fecha y hora en orden ascendente.\n",
        "\n",
        "2. **Transformar datos:**\n",
        "   - Incrementa la columna `vehiculos` en un formato que permita visualizar mejor la cantidad de vehículos (por ejemplo, en miles).\n",
        "   - Limpia cualquier espacio en blanco en la columna `zona`.\n",
        "\n",
        "3. **Combinar dataframes:**\n",
        "   - Combina el DataFrame de tráfico con el DataFrame meteorológico usando la columna `fecha` para unir los datos.\n",
        "\n",
        "4. **Agrupar y analizar:**\n",
        "   - Agrupa los datos combinados por `zona` y `hora` para calcular el promedio de vehículos y la temperatura máxima en cada zona por hora.\n",
        "   - Calcula la cantidad promedio de vehículos en función de la `precipitacion` para identificar si hay una correlación entre la precipitación y el tráfico.\n",
        "\n",
        "5. **Mostrar resultados:**\n",
        "   - Muestra los resultados obtenidos en un nuevo DataFrame.\n",
        "\n",
        "---\n",
        "\n",
        "¡Buena suerte con el análisis de datos de tráfico! Asegúrate de verificar las relaciones entre el tráfico y el clima para obtener conclusiones útiles.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Hvp_v7Yv0Ako"
      }
    }
  ]
}